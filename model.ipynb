{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkfGYtqUFCsV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e84f3750-e7e9-4d48-9b42-bcbdbbef24c9"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlWR3GefFUVm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "#import seasborn as sns\n",
        "%matplotlib inline\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLh_Oxitf4QP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation,Bidirectional, Lambda, Dot\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.models import Model\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from keras.activations import softmax\n",
        "from keras.layers import Bidirectional,dot, Reshape, add, BatchNormalization, concatenate,Flatten\n",
        "from keras.layers import Lambda, Permute, Concatenate, Multiply,GlobalAvgPool1D,GlobalMaxPool1D\n",
        "from keras import backend as K"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYDSPCL8NRz0",
        "colab_type": "text"
      },
      "source": [
        "Initial Data Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4Wv2tuMGq7z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "ac718f3f-39a2-4b69-8583-9a54f02841cc"
      },
      "source": [
        "train  = pd.read_csv(\"train.csv\").fillna(\"\")\n",
        "train.head()\n",
        "test = pd.read_csv(\"test.csv\").fillna(\"\")\n",
        "test.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>test_id</th>\n",
              "      <th>question1</th>\n",
              "      <th>question2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>How does the Surface Pro himself 4 compare wit...</td>\n",
              "      <td>Why did Microsoft choose core m3 and not core ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Should I have a hair transplant at age 24? How...</td>\n",
              "      <td>How much cost does hair transplant require?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>What but is the best way to send money from Ch...</td>\n",
              "      <td>What you send money to China?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Which food not emulsifiers?</td>\n",
              "      <td>What foods fibre?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>How \"aberystwyth\" start reading?</td>\n",
              "      <td>How their can I start reading?</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   test_id  ...                                          question2\n",
              "0        0  ...  Why did Microsoft choose core m3 and not core ...\n",
              "1        1  ...        How much cost does hair transplant require?\n",
              "2        2  ...                      What you send money to China?\n",
              "3        3  ...                                  What foods fibre?\n",
              "4        4  ...                     How their can I start reading?\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAJpHhz_HSPD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "outputId": "cdb7f6f6-5239-47ef-b35f-605feb568b4b"
      },
      "source": [
        "#class imbalance\n",
        "print (train.groupby(\"is_duplicate\")['id'].count())\n",
        "ids = pd.Series(train['qid1'].tolist() + train['qid2'].tolist())\n",
        "#unique ids\n",
        "print (len(np.unique(ids)))\n",
        "plt.figure(figsize=(5, 5))\n",
        "plt.hist(ids.value_counts(), bins=200)\n",
        "plt.yscale('log')\n",
        "plt.title('Histogram showing question appearence frequencies')\n",
        "plt.xlabel('Total Number of occurences of question')\n",
        "plt.ylabel('Total Number of questions')\n",
        "#Max number of times a question has appeared\n",
        "print (max(ids.value_counts()))\n",
        "\n",
        "plt.bar([0, 1], [255027, 149263])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "is_duplicate\n",
            "0    255027\n",
            "1    149263\n",
            "Name: id, dtype: int64\n",
            "537933\n",
            "157\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSU4xkW7g_Ek",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "outputId": "b1035e21-0423-45fe-8af8-17c2eea838a4"
      },
      "source": [
        "train.groupby(\"is_duplicate\")['id'].count().plot.bar()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f5ee5612470>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aopY16X1aZNo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "8eb69eec-838a-49f2-e41f-74b8a538d63a"
      },
      "source": [
        "train['length_q1'] = train['question1'].str.len() \n",
        "train['length_q2'] = train['question2'].str.len()\n",
        "\n",
        "train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>qid1</th>\n",
              "      <th>qid2</th>\n",
              "      <th>question1</th>\n",
              "      <th>question2</th>\n",
              "      <th>is_duplicate</th>\n",
              "      <th>length_q1</th>\n",
              "      <th>length_q2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>What is the step by step guide to invest in sh...</td>\n",
              "      <td>What is the step by step guide to invest in sh...</td>\n",
              "      <td>0</td>\n",
              "      <td>66</td>\n",
              "      <td>57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
              "      <td>What would happen if the Indian government sto...</td>\n",
              "      <td>0</td>\n",
              "      <td>51</td>\n",
              "      <td>88</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>How can I increase the speed of my internet co...</td>\n",
              "      <td>How can Internet speed be increased by hacking...</td>\n",
              "      <td>0</td>\n",
              "      <td>73</td>\n",
              "      <td>59</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
              "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
              "      <td>0</td>\n",
              "      <td>50</td>\n",
              "      <td>65</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "      <td>10</td>\n",
              "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
              "      <td>Which fish would survive in salt water?</td>\n",
              "      <td>0</td>\n",
              "      <td>76</td>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  qid1  qid2  ... is_duplicate length_q1  length_q2\n",
              "0   0     1     2  ...            0        66         57\n",
              "1   1     3     4  ...            0        51         88\n",
              "2   2     5     6  ...            0        73         59\n",
              "3   3     7     8  ...            0        50         65\n",
              "4   4     9    10  ...            0        76         39\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTjjuDSkfaPa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "b090c20e-27a8-410f-8ba2-babe3b947ae0"
      },
      "source": [
        "train['words_q1'] = train['question1'].apply(lambda row: len(row.split(\" \")))\n",
        "train['words_q2'] = train['question2'].apply(lambda row: len(row.split(\" \")))\n",
        "train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>qid1</th>\n",
              "      <th>qid2</th>\n",
              "      <th>question1</th>\n",
              "      <th>question2</th>\n",
              "      <th>is_duplicate</th>\n",
              "      <th>length_q1</th>\n",
              "      <th>length_q2</th>\n",
              "      <th>words_q1</th>\n",
              "      <th>words_q2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>What is the step by step guide to invest in sh...</td>\n",
              "      <td>What is the step by step guide to invest in sh...</td>\n",
              "      <td>0</td>\n",
              "      <td>66</td>\n",
              "      <td>57</td>\n",
              "      <td>14</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
              "      <td>What would happen if the Indian government sto...</td>\n",
              "      <td>0</td>\n",
              "      <td>51</td>\n",
              "      <td>88</td>\n",
              "      <td>8</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>How can I increase the speed of my internet co...</td>\n",
              "      <td>How can Internet speed be increased by hacking...</td>\n",
              "      <td>0</td>\n",
              "      <td>73</td>\n",
              "      <td>59</td>\n",
              "      <td>14</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
              "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
              "      <td>0</td>\n",
              "      <td>50</td>\n",
              "      <td>65</td>\n",
              "      <td>11</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "      <td>10</td>\n",
              "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
              "      <td>Which fish would survive in salt water?</td>\n",
              "      <td>0</td>\n",
              "      <td>76</td>\n",
              "      <td>39</td>\n",
              "      <td>13</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  qid1  qid2  ... length_q2 words_q1  words_q2\n",
              "0   0     1     2  ...        57       14        12\n",
              "1   1     3     4  ...        88        8        13\n",
              "2   2     5     6  ...        59       14        10\n",
              "3   3     7     8  ...        65       11         9\n",
              "4   4     9    10  ...        39       13         7\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgsFkFW_iOXu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "combine  = pd.concat([train[['question1', 'question2']], test[['question1', 'question2']]], axis=0).reset_index(drop='index')\n",
        "combine.head()\n",
        "from collections import defaultdict\n",
        "dictionary = defaultdict(set)\n",
        "for i in range(combine.shape[0]):\n",
        "        dictionary[combine.question1[i]].add(combine.question2[i])\n",
        "        dictionary[combine.question2[i]].add(combine.question1[i])\n",
        "\n",
        "def similar_words(row):\n",
        "    w1 = set(map(lambda word: word.lower().strip(), row['question1'].split(\" \")))\n",
        "    w2 = set(map(lambda word: word.lower().strip(), row['question2'].split(\" \")))    \n",
        "    return 1.0 * len(w1 & w2)/(len(w1) + len(w2))        \n",
        "def netq1_f(row):\n",
        "    return(len(dictionary[row['question1']]))    \n",
        "def netq2_f(row):\n",
        "    return(len(dictionary[row['question2']]))    \n",
        "def netpair_f(row):\n",
        "    return(len(set(dictionary[row['question1']]).intersection(set(dictionary[row['question2']]))))\n",
        "train['similar_word'] = train.apply(similar_words, axis=1)\n",
        "train['netpair_f'] = train.apply(netpair_f, axis=1, raw=True)\n",
        "train['netq1_f'] = train.apply(netq1_f, axis=1, raw=True)\n",
        "train['netq2_f'] = train.apply(netq2_f, axis=1, raw=True)\n",
        "\n",
        "test['netpair_f'] = test.apply(netpair_f, axis=1, raw=True)\n",
        "test['netq1_f'] = test.apply(netq1_f, axis=1, raw=True)\n",
        "test['netq2_f'] = test.apply(netq2_f, axis=1, raw=True)\n",
        "test['similar_word'] = test.apply(similar_words,axis = 1)\n",
        "train_extra = train[[ 'netq1_f', 'netq2_f','netpair_f','similar_word']]\n",
        "test_extra = test[[ 'netq1_f', 'netq2_f','netpair_f','similar_word']]\n",
        "scaling = StandardScaler()\n",
        "scaling.fit(np.vstack((train_extra, test_extra)))\n",
        "train_extra = scaling.transform(train_extra)\n",
        "test_extra = scaling.transform(test_extra)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WpIZ0CQxNIiL",
        "colab_type": "text"
      },
      "source": [
        "Processing of Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3xB94IeiZczQ",
        "colab": {}
      },
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ElxXuaKeUgoP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Stopwords were not removed because they might have crucial info as we are dealing with questions in the context\n",
        "def text_to_word(text):\n",
        "\n",
        "    text = str(text)\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"[^A-Za-z0-9]\", \" \", text)\n",
        "    text = re.sub(r\"what's\", \"\", text)\n",
        "    text = re.sub(r\"What's\", \"\", text)\n",
        "    text = re.sub(r\"\\'s\", \" \", text)\n",
        "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
        "    text = re.sub(r\"can't\", \"cannot \", text)\n",
        "    text = re.sub(r\"n't\", \" not \", text)\n",
        "    text = re.sub(r\"I'm\", \"I am\", text)\n",
        "    text = re.sub(r\" m \", \" am \", text)\n",
        "    text = re.sub(r\"\\'re\", \" are \", text)\n",
        "    text = re.sub(r\"\\'d\", \" would \", text)\n",
        "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
        "    text = re.sub(r\"60k\", \" 60000 \", text)\n",
        "    text = re.sub(r\" e g \", \" eg \", text)\n",
        "    text = re.sub(r\" b g \", \" bg \", text)\n",
        "    text = re.sub(r\"\\0s\", \"0\", text)\n",
        "    text = re.sub(r\" 9 11 \", \"911\", text)\n",
        "\n",
        "    ps = PorterStemmer()\n",
        "    text = text.split()\n",
        "    stemmed_words = [ps.stem(word) for word in text]\n",
        "    text = \" \".join(stemmed_words)\n",
        "    \n",
        "    return(text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvYc3vBpWEga",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#cleaning data\n",
        "train_q1 = []\n",
        "train_q2 = []\n",
        "test_q1 = []\n",
        "test_q2 = []\n",
        "for item in train['question1']:\n",
        "  train_q1.append(text_to_word(item))\n",
        "for item in train['question2']:\n",
        "  train_q2.append(text_to_word(item))\n",
        "for item in test['question1']:\n",
        "  test_q1.append(text_to_word(item))\n",
        "for item in test['question2']:\n",
        "  test_q2.append(text_to_word(item))   \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_Rhe6OM9FKS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 632
        },
        "outputId": "848446be-164c-4163-e220-2fd0c0b892c1"
      },
      "source": [
        "train['q1_clean'] = train_q1\n",
        "train['q2_clean'] = train_q2\n",
        "test['q1_clean'] = test_q1\n",
        "test['q2_clean'] = test_q2\n",
        "train.head()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>qid1</th>\n",
              "      <th>qid2</th>\n",
              "      <th>question1</th>\n",
              "      <th>question2</th>\n",
              "      <th>is_duplicate</th>\n",
              "      <th>length_q1</th>\n",
              "      <th>length_q2</th>\n",
              "      <th>words_q1</th>\n",
              "      <th>words_q2</th>\n",
              "      <th>similar_word</th>\n",
              "      <th>netpair_f</th>\n",
              "      <th>netq1_f</th>\n",
              "      <th>netq2_f</th>\n",
              "      <th>q1_clean</th>\n",
              "      <th>q2_clean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>What is the step by step guide to invest in sh...</td>\n",
              "      <td>What is the step by step guide to invest in sh...</td>\n",
              "      <td>0</td>\n",
              "      <td>66</td>\n",
              "      <td>57</td>\n",
              "      <td>14</td>\n",
              "      <td>12</td>\n",
              "      <td>0.434783</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>what is the step by step guid to invest in sha...</td>\n",
              "      <td>what is the step by step guid to invest in sha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
              "      <td>What would happen if the Indian government sto...</td>\n",
              "      <td>0</td>\n",
              "      <td>51</td>\n",
              "      <td>88</td>\n",
              "      <td>8</td>\n",
              "      <td>13</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>what is the stori of kohinoor koh i noor diamond</td>\n",
              "      <td>what would happen if the indian govern stole t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>How can I increase the speed of my internet co...</td>\n",
              "      <td>How can Internet speed be increased by hacking...</td>\n",
              "      <td>0</td>\n",
              "      <td>73</td>\n",
              "      <td>59</td>\n",
              "      <td>14</td>\n",
              "      <td>10</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>how can i increas the speed of my internet con...</td>\n",
              "      <td>how can internet speed be increas by hack thro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
              "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
              "      <td>0</td>\n",
              "      <td>50</td>\n",
              "      <td>65</td>\n",
              "      <td>11</td>\n",
              "      <td>9</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>whi am i mental veri lone how can i solv it</td>\n",
              "      <td>find the remaind when math 23 24 math is divid...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "      <td>10</td>\n",
              "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
              "      <td>Which fish would survive in salt water?</td>\n",
              "      <td>0</td>\n",
              "      <td>76</td>\n",
              "      <td>39</td>\n",
              "      <td>13</td>\n",
              "      <td>7</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>which one dissolv in water quikli sugar salt m...</td>\n",
              "      <td>which fish would surviv in salt water</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  ...                                           q2_clean\n",
              "0   0  ...  what is the step by step guid to invest in sha...\n",
              "1   1  ...  what would happen if the indian govern stole t...\n",
              "2   2  ...  how can internet speed be increas by hack thro...\n",
              "3   3  ...  find the remaind when math 23 24 math is divid...\n",
              "4   4  ...              which fish would surviv in salt water\n",
              "\n",
              "[5 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Wbdm_wOZh5U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Tokenisation\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(train_q1+train_q2+test_q1+test_q2)\n",
        "train['q1_tokenised'] = tokenizer.texts_to_sequences(train['q1_clean'])\n",
        "train['q2_tokenised'] = tokenizer.texts_to_sequences(train['q2_clean'])\n",
        "test['q1_tokenised'] = tokenizer.texts_to_sequences(test['q1_clean'])\n",
        "test['q2_tokenised'] = tokenizer.texts_to_sequences(test['q2_clean'])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2Ol7eeyDku5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Apply padding\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "q1_train_padded = pad_sequences(train['q1_tokenised'], maxlen=30)\n",
        "q2_train_padded = pad_sequences(train['q2_tokenised'], maxlen=30)\n",
        "q1_test_padded = pad_sequences(test['q1_tokenised'], maxlen=30)\n",
        "q2_test_padded = pad_sequences(test['q2_tokenised'], maxlen=30)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3k-c0FRYwXg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Data Augmentation\n",
        "final_train_q1 = np.vstack((q1_train_padded,q2_train_padded))\n",
        "final_train_q2 = np.vstack((q2_train_padded,q1_train_padded))\n",
        "final_train_extra = np.vstack((train_extra,train_extra))\n",
        "final_test_q1 = np.vstack((q1_test_padded,q2_test_padded))\n",
        "final_test_q2 = np.vstack((q2_test_padded,q1_test_padded))\n",
        "final_test_extra = np.vstack((test_extra,test_extra))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqlw2AukhnlB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels_train = np.concatenate((train['is_duplicate'], train['is_duplicate']))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IpFlfVapaJGY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Embeddings Use this format for txt/vec file have glove and fasttext files for these\n",
        "embeddingfile = 'glove.6B.300d.txt'\n",
        "#embeddingfile = 'wiki-news-300d-1M.vec'\n",
        "embeddings_index = {}\n",
        "f = open(embeddingfile)\n",
        "count = 0\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "\n",
        "\n",
        "#Embedding use this format for .bin file, for googlenews file use the code below\n",
        "\n",
        "#embeddingfile = 'GoogleNews-vectors-negative300.bin.gz'\n",
        "#embeddings_index = {}\n",
        "#from gensim.models import KeyedVectors\n",
        "#wv_from_bin = KeyedVectors.load_word2vec_format(EMBEDDING_FILE, binary=True) \n",
        "#for word, vector in zip(wv_from_bin.vocab, wv_from_bin.vectors):\n",
        "#    coefs = np.asarray(vector, dtype='float32')\n",
        "#    embeddings_index[word] = coefs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fWv2f9DcOhM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = np.max(final_test_q1.max())\n",
        "b = np.max(final_test_q2.max())\n",
        "c = np.max(final_train_q1.max())\n",
        "d = np.max(final_train_q2.max())\n",
        "Total_words = max(a,b,c,d)\n",
        "\n",
        "nb_words = min(Total_words, len(tokenizer.word_index))+1\n",
        "\n",
        "embedding_matrix = np.zeros((nb_words, 300))\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OhlDbmVC10y6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def recall_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "def f1_m(y_true, y_pred):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDeWPuwgw86H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#MaLSTM model\n",
        "embedding_layer = Embedding(nb_words,300,weights=[embedding_matrix],input_length=30,trainable=False)\n",
        "lstm = LSTM(200)\n",
        "q1 = Input(shape=(30,),)\n",
        "q2 = Input(shape=(30,),)\n",
        "a1 = embedding_layer(q1)\n",
        "a2 = embedding_layer(q2)\n",
        "x1 = lstm(a1)\n",
        "x2 = lstm(a2)\n",
        "def exponential_negative_manhattan_distance(left, right):\n",
        "     return K.exp(-K.sum(K.abs(left-right), axis=1, keepdims=True))\n",
        "d = Lambda(function=lambda x: exponential_negative_manhattan_distance(x[0], x[1]),output_shape=lambda x: (x[0][0], 1))([x1, x2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARE6znEGrUmO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Siamese model\n",
        "embedding_layer = Embedding(nb_words,300,weights=[embedding_matrix],input_length=30,trainable=False)\n",
        "lstm = LSTM(200)\n",
        "q1 = Input(shape=(30,),)\n",
        "q2 = Input(shape=(30,),)\n",
        "a1 = embedding_layer(q1)\n",
        "a2 = embedding_layer(q2)\n",
        "x1 = lstm(a1)\n",
        "x2 = lstm(a2)\n",
        "x = concatenate([x1,x2])\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.2)(x)\n",
        "x = Dense(200, activation='relu')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.2)(x)\n",
        "y_pred = Dense(1, activation='sigmoid')(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRsXzYDAr9tU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_layer = Embedding(nb_words,300,weights=[embedding_matrix],input_length=30,trainable=False)\n",
        "q1 = Input(shape=(30,),)\n",
        "q2 = Input(shape=(30,),)\n",
        "e = Input(shape=(final_train_extra.shape[1],))\n",
        "a1 = embedding_layer(q1)\n",
        "a2 = embedding_layer(q2)\n",
        "#w1 = LSTM(200, return_sequences=True)(a1)\n",
        "w1 = Bidirectional(LSTM(200, return_sequences=True),name ='BiLSTM1')(a1)\n",
        "#w2 = LSTM(200, return_sequences=True)(a2)\n",
        "w2 = Bidirectional(LSTM(200, return_sequences=True),name = 'BiLSTM2')(a2)\n",
        "#Align part\n",
        "F = Dot(axes=-1)([w1, w2])\n",
        "alpha_attention = Lambda(lambda x: softmax(x, axis=1))(F)\n",
        "beta_attention = Permute((2,1))(Lambda(lambda x: softmax(x, axis=2))(F))\n",
        "alpha = Dot(axes=1)([alpha_attention, w1])\n",
        "beta = Dot(axes=1)([beta_attention, w2])\n",
        "alligned_phrase_1 = concatenate([w1, beta])\n",
        "alligned_phrase_2 = concatenate([w2, alpha]) \n",
        "G = LSTM(200, return_sequences=True)\n",
        "Va_i = G(alligned_phrase_1)\n",
        "Vb_i = G(alligned_phrase_2)\n",
        "p1 = GlobalAvgPool1D()\n",
        "p2 = GlobalAvgPool1D()\n",
        "Va = p1(Va_i)\n",
        "Vb = p2(Vb_i)\n",
        "#extra = Dense(200, activation='relu')(e)\n",
        "H = concatenate([Va, Vb])\n",
        "#H = concatenate([Va,Vb,extra])\n",
        "H = BatchNormalization()(H)\n",
        "H = Dense(1000, activation='relu')(H)\n",
        "H = Dropout(0.1)(H)\n",
        "H = BatchNormalization()(H)\n",
        "H = Dense(500, activation='relu')(H)\n",
        "H = Dropout(0.1)(H)\n",
        "H = BatchNormalization()(H)\n",
        "H = Dense(200, activation='relu')(H)\n",
        "H = Dropout(0.1)(H)\n",
        "H = BatchNormalization()(H)\n",
        "\n",
        "y_pred = Dense(1, activation='sigmoid')(H)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKTROi_rgrh_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Use this for MaLSTM model\n",
        "model = Model([q1, q2], [d])\n",
        "early_stopping =EarlyStopping(monitor='val_loss', patience=10)\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc',f1_m,precision_m, recall_m])\n",
        "Result = model.fit([final_train_q1, final_train_q2], labels_train,validation_split=0.2,batch_size = 10000,  epochs= 30, class_weight = {0: 1.309028344, 1: 0.472001959}, callbacks=[early_stopping])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2PH3ogOuxXp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "028819e5-515d-4e7b-afb4-36912e1fc10d"
      },
      "source": [
        "#Use this for Simaese and Decomposable attention \n",
        "model = Model([q1, q2], y_pred)\n",
        "early_stopping =EarlyStopping(monitor='val_loss', patience=10)\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc',f1_m,precision_m, recall_m])\n",
        "Result = model.fit([final_train_q1, final_train_q2], labels_train,validation_split=0.2,batch_size = 10000,  epochs= 30,class_weight = {0: 1.309028344, 1: 0.472001959}, callbacks=[early_stopping])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 646864 samples, validate on 161716 samples\n",
            "Epoch 1/30\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SEQfeCWl_bQx",
        "colab": {}
      },
      "source": [
        "#Use this for Decomposable attention with extra features\n",
        "model = Model([q1, q2, e], y_pred)\n",
        "early_stopping =EarlyStopping(monitor='val_loss', patience=10)\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc',f1_m,precision_m, recall_m])\n",
        "Result = model.fit([final_train_q1, final_train_q2,final_train_extra ], labels_train,validation_split=0.2,batch_size = 10000,  epochs= 30,class_weight = {0: 1.309028344, 1: 0.472001959})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYum-qP7CgYx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(Result.history['acc'])\n",
        "plt.plot(Result.history['val_acc'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(Result.history['loss'])\n",
        "plt.plot(Result.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-15Ti28s6LS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediction1 = model.predict([q1_test_padded, q2_test_padded],batch_size = 10000, verbose =1)\n",
        "prediction2 = model.predict([q2_test_padded, q1_test_padded],batch_size = 10000, verbose =1)\n",
        "prediction = (prediction1 + prediction2)/2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_KNZ8tkMvRYz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submission = pd.DataFrame({'test_id':np.arange(len(preds)), 'is_duplicate':prediction.ravel()})\n",
        "submission.to_csv('sample_submission.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWf4S4yWEZYu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install scikit-plot\n",
        "y_predict = np.where(prediction > 0.5, 1, 0)\n",
        "import scikitplot as skplt \n",
        "skplt.metrics.plot_confusion_matrix( labels,y_predict, normalize=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rkk0R3l1CAT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils import plot_model\n",
        "plot_model(model,to_file=\"model.png\")\n",
        "from IPython.display import Image\n",
        "Image(filename='model.png')\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}